{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetching and saving raw data...\n",
      "Fetching data for META\n",
      "Successfully saved raw data for META\n",
      "Fetching data for AAPL\n",
      "Successfully saved raw data for AAPL\n",
      "Fetching data for AMZN\n",
      "Successfully saved raw data for AMZN\n",
      "Fetching data for NFLX\n",
      "Successfully saved raw data for NFLX\n",
      "Fetching data for GOOG\n",
      "Successfully saved raw data for GOOG\n",
      "Fetching data for ^GSPC\n",
      "Successfully saved raw data for ^GSPC\n",
      "Fetching data for BTC-USD\n",
      "Successfully saved raw data for BTC-USD\n",
      "Fetching data for GC=F\n",
      "Successfully saved raw data for GC=F\n",
      "\n",
      "Step 2: Cleaning and saving processed data...\n",
      "Cleaning data for META\n",
      "Successfully cleaned and saved data for META\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date       Close        High         Low        Open      Volume\n",
      "1 2024-01-03  343.159149  346.625917  341.874050  343.667218  15451100.0\n",
      "2 2024-01-04  345.799072  346.825152  342.093227  343.189047  12099900.0\n",
      "3 2024-01-05  350.610687  352.154777  344.942338  345.669540  13920700.0\n",
      "\n",
      "\n",
      "Cleaning data for AAPL\n",
      "Successfully cleaned and saved data for AAPL\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date       Close        High         Low        Open      Volume\n",
      "1 2024-01-03  183.351746  184.973804  182.535736  183.321893  58414500.0\n",
      "2 2024-01-04  181.023178  182.197418  179.998201  181.261998  71983600.0\n",
      "3 2024-01-05  180.296692  181.868991  179.291621  181.102756  62303300.0\n",
      "\n",
      "\n",
      "Cleaning data for AMZN\n",
      "Successfully cleaned and saved data for AMZN\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date       Close        High         Low        Open      Volume\n",
      "1 2024-01-03  148.470001  151.050003  148.330002  149.199997  49425500.0\n",
      "2 2024-01-04  144.570007  147.380005  144.050003  145.589996  56039800.0\n",
      "3 2024-01-05  145.240005  146.589996  144.529999  144.690002  45124800.0\n",
      "\n",
      "\n",
      "Cleaning data for NFLX\n",
      "Successfully cleaned and saved data for NFLX\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date       Close        High         Low        Open     Volume\n",
      "1 2024-01-03  470.260010  475.049988  465.769989  467.320007  3443700.0\n",
      "2 2024-01-04  474.670013  480.739990  466.529999  472.980011  3636500.0\n",
      "3 2024-01-05  474.059998  479.549988  471.799988  476.500000  2612500.0\n",
      "\n",
      "\n",
      "Cleaning data for GOOG\n",
      "Successfully cleaned and saved data for GOOG\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date       Close        High         Low        Open      Volume\n",
      "1 2024-01-03  139.857483  140.584865  137.934385  138.103790  18974300.0\n",
      "2 2024-01-04  137.545776  140.131487  137.515885  139.349309  18253300.0\n",
      "3 2024-01-05  136.898117  138.313031  136.360057  137.856679  15433200.0\n",
      "\n",
      "\n",
      "Cleaning data for ^GSPC\n",
      "Successfully cleaned and saved data for ^GSPC\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date        Close         High          Low         Open        Volume\n",
      "1 2024-01-03  4704.810059  4729.290039  4699.709961  4725.069824  3.950760e+09\n",
      "2 2024-01-04  4688.680176  4726.779785  4687.529785  4697.419922  3.715480e+09\n",
      "3 2024-01-05  4697.240234  4721.490234  4682.109863  4690.569824  3.844370e+09\n",
      "\n",
      "\n",
      "Cleaning data for BTC-USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned and saved data for BTC-USD\n",
      "Number of rows: 364\n",
      "First few rows:\n",
      "        Date         Close          High           Low          Open  \\\n",
      "1 2024-01-02  44957.968750  45899.707031  44176.949219  44187.140625   \n",
      "2 2024-01-03  42848.175781  45503.242188  40813.535156  44961.601562   \n",
      "3 2024-01-04  44179.921875  44770.023438  42675.175781  42855.816406   \n",
      "\n",
      "         Volume  \n",
      "1  3.933527e+10  \n",
      "2  4.634232e+10  \n",
      "3  3.044809e+10  \n",
      "\n",
      "\n",
      "Cleaning data for GC=F\n",
      "Successfully cleaned and saved data for GC=F\n",
      "Number of rows: 250\n",
      "First few rows:\n",
      "        Date        Close         High          Low         Open  Volume\n",
      "1 2024-01-03  2034.199951  2044.000000  2034.199951  2034.199951    54.0\n",
      "2 2024-01-04  2042.300049  2044.500000  2038.000000  2041.599976    88.0\n",
      "3 2024-01-05  2042.400024  2048.100098  2042.400024  2044.500000    12.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Define the directory for datasets\n",
    "dataset_dir = r\"C:\\Users\\alanm\\OneDrive\\Documents\\MADS\\Capstone1\\GitHub_Project\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "def fetch_and_save_stock_data(ticker):\n",
    "    \"\"\"\n",
    "    Fetches stock data and saves it with the required column names\n",
    "    \"\"\"\n",
    "    # Download data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Reset index to get Date as a column\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    # Rename 'Date' to 'Price' for consistency with existing files\n",
    "    data = data.rename(columns={'Date': 'Price'})\n",
    "    \n",
    "    # Reorder columns\n",
    "    data = data[['Price', 'Close', 'High', 'Low', 'Open', 'Volume']]\n",
    "    \n",
    "    # Save in raw format\n",
    "    filepath = os.path.join(dataset_dir, f\"{ticker.replace('^', '').replace('=', '_')}_data.csv\")\n",
    "    data.to_csv(filepath, index=False)\n",
    "    return data\n",
    "\n",
    "def clean_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Cleans a dataset to ensure proper format:\n",
    "    - Rename Price to Date\n",
    "    - Remove empty rows and row 2\n",
    "    - Ensure proper data types\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Rename 'Price' column to 'Date'\n",
    "    if 'Price' in df.columns:\n",
    "        df = df.rename(columns={'Price': 'Date'})\n",
    "    \n",
    "    # Remove row 2 and any empty rows\n",
    "    df = df.dropna(how='all')  # Remove completely empty rows\n",
    "    if len(df) > 2:  # Make sure we have enough rows\n",
    "        df = pd.concat([df.iloc[:1], df.iloc[2:]]).reset_index(drop=True)\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Convert numeric columns to appropriate types\n",
    "    numeric_columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Drop any rows with NaN values after conversion\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Ensure correct column order\n",
    "    df = df[['Date', 'Close', 'High', 'Low', 'Open', 'Volume']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define tickers\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOG', '^GSPC', 'BTC-USD', 'GC=F']\n",
    "\n",
    "# Step 1: Fetch and save all data\n",
    "print(\"Step 1: Fetching and saving raw data...\")\n",
    "raw_data = {}\n",
    "for ticker in tickers:\n",
    "    print(f\"Fetching data for {ticker}\")\n",
    "    try:\n",
    "        raw_data[ticker] = fetch_and_save_stock_data(ticker)\n",
    "        print(f\"Successfully saved raw data for {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {str(e)}\")\n",
    "\n",
    "# Step 2: Clean all datasets\n",
    "print(\"\\nStep 2: Cleaning and saving processed data...\")\n",
    "cleaned_data = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        input_path = os.path.join(dataset_dir, f\"{ticker.replace('^', '').replace('=', '_')}_data.csv\")\n",
    "        print(f\"Cleaning data for {ticker}\")\n",
    "        \n",
    "        # Clean the dataset\n",
    "        cleaned_data[ticker] = clean_dataset(input_path)\n",
    "        \n",
    "        # Save cleaned data\n",
    "        output_path = os.path.join(dataset_dir, f\"{ticker.replace('^', '').replace('=', '_')}_cleaned.csv\")\n",
    "        cleaned_data[ticker].to_csv(output_path, index=False)\n",
    "        \n",
    "        # Verify the output\n",
    "        print(f\"Successfully cleaned and saved data for {ticker}\")\n",
    "        print(f\"Number of rows: {len(cleaned_data[ticker])}\")\n",
    "        print(\"First few rows:\")\n",
    "        print(cleaned_data[ticker].head(3))\n",
    "        print(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
